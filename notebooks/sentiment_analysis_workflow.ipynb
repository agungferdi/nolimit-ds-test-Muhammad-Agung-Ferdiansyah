{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3855a55",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Classification with Hugging Face\n",
    "\n",
    "## NoLimit Indonesia - Data Scientist Hiring Test\n",
    "\n",
    "**Objective:** Build NLP solutions using Hugging Face models and embeddings with clean delivery and clear workflow.\n",
    "\n",
    "**Task:** Classification - Sentiment Analysis on Movie Reviews\n",
    "\n",
    "**Author:** Ferdiansyah Muhammad Agung\n",
    "\n",
    "---\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This notebook demonstrates a complete sentiment analysis pipeline using:\n",
    "- **Hugging Face Transformers** for sentiment classification\n",
    "- **Sentence-Transformers** for text embeddings\n",
    "- **FAISS** for similarity search\n",
    "- **Comprehensive evaluation** and visualization\n",
    "\n",
    "### Pipeline Steps\n",
    "1. Data Loading and Exploration\n",
    "2. Model Setup and Configuration\n",
    "3. Sentiment Classification\n",
    "4. Embeddings Creation\n",
    "5. FAISS Similarity Search\n",
    "6. Model Evaluation\n",
    "7. Results Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512ba02",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install transformers sentence-transformers torch datasets pandas numpy scikit-learn matplotlib seaborn plotly faiss-cpu tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1502f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ML and NLP libraries\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Configure warnings and logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5fcb0",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample dataset\n",
    "data_path = '../data/sample_reviews.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f636766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics\n",
    "print(\"üìä Dataset Statistics\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Text length statistics\n",
    "df['text_length'] = df['text'].str.len()\n",
    "print(f\"\\nText length statistics:\")\n",
    "print(df['text_length'].describe())\n",
    "\n",
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar plot\n",
    "label_counts.plot(kind='bar', ax=axes[0], color=['#ff6b6b', '#4ecdc4', '#45b7d1'])\n",
    "axes[0].set_title('Label Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Text length distribution\n",
    "df.boxplot(column='text_length', by='label', ax=axes[1])\n",
    "axes[1].set_title('Text Length by Sentiment')\n",
    "axes[1].set_xlabel('Sentiment')\n",
    "axes[1].set_ylabel('Text Length')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1935779b",
   "metadata": {},
   "source": [
    "## 3. Model Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom sentiment classifier\n",
    "from models.sentiment_classifier import SentimentClassifier\n",
    "\n",
    "# Initialize the sentiment classifier\n",
    "print(\"ü§ñ Initializing Sentiment Classifier...\")\n",
    "print(\"Loading models from Hugging Face...\")\n",
    "\n",
    "classifier = SentimentClassifier(\n",
    "    classification_model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    embedding_model=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Models loaded successfully!\")\n",
    "print(f\"Classification model: {classifier.classification_model_name}\")\n",
    "print(f\"Embedding model: {classifier.embedding_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec90d9",
   "metadata": {},
   "source": [
    "## 4. Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e74393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single prediction\n",
    "test_text = \"This movie is absolutely fantastic! I loved every minute of it.\"\n",
    "result = classifier.predict_sentiment(test_text)\n",
    "\n",
    "print(\"üß™ Single Prediction Test\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Text: {result['text']}\")\n",
    "print(f\"Predicted Sentiment: {result['sentiment']}\")\n",
    "print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "print(f\"All Scores: {result['all_scores']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch prediction on sample data\n",
    "print(\"üöÄ Running batch predictions...\")\n",
    "sample_texts = df['text'].tolist()[:10]  # Test on first 10 samples\n",
    "\n",
    "batch_results = classifier.predict_batch(sample_texts)\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(batch_results)\n",
    "print(\"\\nüìã Batch Prediction Results (First 10 samples):\")\n",
    "for i, result in enumerate(batch_results):\n",
    "    print(f\"\\n{i+1}. Text: {result['text'][:60]}...\")\n",
    "    print(f\"   Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253723b9",
   "metadata": {},
   "source": [
    "## 5. Embeddings Creation and FAISS Index Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for all texts\n",
    "print(\"üîÆ Creating embeddings for all texts...\")\n",
    "all_texts = df['text'].tolist()\n",
    "\n",
    "start_time = time.time()\n",
    "embeddings = classifier.create_embeddings(all_texts)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"‚úÖ Embeddings created!\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Build FAISS index\n",
    "print(\"\\nüîç Building FAISS index for similarity search...\")\n",
    "classifier.build_faiss_index(all_texts, embeddings)\n",
    "print(\"‚úÖ FAISS index built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fcb157",
   "metadata": {},
   "source": [
    "## 6. Similarity Search Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3205c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test similarity search\n",
    "query_text = \"This movie is amazing and beautiful!\"\n",
    "\n",
    "print(f\"üîç Finding similar texts for: '{query_text}'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "similar_texts = classifier.find_similar_texts(query_text, k=5)\n",
    "\n",
    "for i, result in enumerate(similar_texts):\n",
    "    print(f\"\\n{result['rank']}. Similarity Score: {result['similarity_score']:.4f}\")\n",
    "    print(f\"   Text: {result['text']}\")\n",
    "    \n",
    "# Combined analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ Combined Sentiment Analysis + Similarity Search\")\n",
    "combined_result = classifier.analyze_sentiment_with_similarity(query_text, k=3)\n",
    "\n",
    "sentiment_analysis = combined_result['sentiment_analysis']\n",
    "print(f\"\\nQuery: {query_text}\")\n",
    "print(f\"Sentiment: {sentiment_analysis['sentiment']} (Confidence: {sentiment_analysis['confidence']:.4f})\")\n",
    "print(f\"\\nTop 3 Similar Texts:\")\n",
    "for result in combined_result['similar_texts']:\n",
    "    print(f\"  ‚Ä¢ {result['text']} (Score: {result['similarity_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4db7b4",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbb57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset prediction for evaluation\n",
    "print(\"üìä Evaluating model on full dataset...\")\n",
    "\n",
    "# Get predictions for all samples\n",
    "all_predictions = []\n",
    "all_confidences = []\n",
    "\n",
    "for text in tqdm(df['text'], desc=\"Predicting\"):\n",
    "    result = classifier.predict_sentiment(text)\n",
    "    all_predictions.append(result['sentiment'])\n",
    "    all_confidences.append(result['confidence'])\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df['predicted_sentiment'] = all_predictions\n",
    "df['confidence'] = all_confidences\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(df['label'], df['predicted_sentiment'])\n",
    "print(f\"\\nüéØ Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(df['label'], df['predicted_sentiment'], output_dict=True)\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(df['label'], df['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309bd839",
   "metadata": {},
   "source": [
    "## 8. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(df['label'], df['predicted_sentiment'])\n",
    "labels = sorted(df['label'].unique())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Confidence distribution by sentiment\n",
    "plt.figure(figsize=(12, 6))\n",
    "for sentiment in df['label'].unique():\n",
    "    subset = df[df['label'] == sentiment]\n",
    "    plt.hist(subset['confidence'], alpha=0.7, label=f'{sentiment}', bins=20)\n",
    "\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Confidence Score Distribution by Sentiment')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive visualization with Plotly\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Accuracy by Sentiment', 'Confidence Distribution', \n",
    "                   'Prediction vs Actual', 'Sample Predictions'),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"histogram\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"table\"}]]\n",
    ")\n",
    "\n",
    "# Accuracy by sentiment\n",
    "accuracy_by_sentiment = df.groupby('label').apply(\n",
    "    lambda x: accuracy_score(x['label'], x['predicted_sentiment'])\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=accuracy_by_sentiment.index, y=accuracy_by_sentiment.values,\n",
    "           name='Accuracy', marker_color='lightblue'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Confidence distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df['confidence'], nbinsx=20, name='Confidence',\n",
    "                marker_color='lightgreen'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Sample predictions table\n",
    "sample_df = df.head(10)[['text', 'label', 'predicted_sentiment', 'confidence']]\n",
    "sample_df['text'] = sample_df['text'].str[:50] + '...'\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(values=list(sample_df.columns),\n",
    "                   fill_color='paleturquoise',\n",
    "                   align='left'),\n",
    "        cells=dict(values=[sample_df[col] for col in sample_df.columns],\n",
    "                  fill_color='lavender',\n",
    "                  align='left')\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Sentiment Analysis Results Dashboard\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b6219",
   "metadata": {},
   "source": [
    "## 9. Embeddings Visualization with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ccf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality for visualization\n",
    "print(\"üé® Creating t-SNE visualization of embeddings...\")\n",
    "\n",
    "# Use a subset for faster computation\n",
    "n_samples = min(len(embeddings), 100)\n",
    "subset_embeddings = embeddings[:n_samples]\n",
    "subset_labels = df['label'][:n_samples]\n",
    "subset_predictions = df['predicted_sentiment'][:n_samples]\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, n_samples-1))\n",
    "embeddings_2d = tsne.fit_transform(subset_embeddings)\n",
    "\n",
    "# Create visualization dataframe\n",
    "viz_df = pd.DataFrame({\n",
    "    'x': embeddings_2d[:, 0],\n",
    "    'y': embeddings_2d[:, 1],\n",
    "    'actual_label': subset_labels,\n",
    "    'predicted_label': subset_predictions,\n",
    "    'text': df['text'][:n_samples].str[:100] + '...'\n",
    "})\n",
    "\n",
    "# Interactive t-SNE plot\n",
    "fig = px.scatter(\n",
    "    viz_df, x='x', y='y', \n",
    "    color='actual_label',\n",
    "    symbol='predicted_label',\n",
    "    hover_data=['text'],\n",
    "    title='t-SNE Visualization of Text Embeddings',\n",
    "    labels={'color': 'Actual Sentiment', 'symbol': 'Predicted Sentiment'}\n",
    ")\n",
    "\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()\n",
    "\n",
    "print(f\"‚úÖ Visualized {n_samples} samples in 2D space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437069fb",
   "metadata": {},
   "source": [
    "## 10. Example Predictions and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some example predictions with explanations\n",
    "example_texts = [\n",
    "    \"This movie is absolutely incredible! Best film ever!\",\n",
    "    \"Terrible movie, complete waste of time and money.\",\n",
    "    \"The movie was okay, nothing special but watchable.\",\n",
    "    \"I'm not sure what to think about this film.\",\n",
    "    \"Mixed feelings about this one - some good, some bad parts.\"\n",
    "]\n",
    "\n",
    "print(\"üé¨ Example Predictions with Similarity Search\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, text in enumerate(example_texts):\n",
    "    print(f\"\\n{i+1}. Text: '{text}'\")\n",
    "    \n",
    "    # Get sentiment and similar texts\n",
    "    result = classifier.analyze_sentiment_with_similarity(text, k=2)\n",
    "    \n",
    "    sentiment = result['sentiment_analysis']\n",
    "    print(f\"   Sentiment: {sentiment['sentiment']} (Confidence: {sentiment['confidence']:.4f})\")\n",
    "    \n",
    "    if result['similar_texts']:\n",
    "        print(\"   Similar texts from dataset:\")\n",
    "        for sim_result in result['similar_texts']:\n",
    "            print(f\"     ‚Ä¢ {sim_result['text']} (Score: {sim_result['similarity_score']:.4f})\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3096fb",
   "metadata": {},
   "source": [
    "## 11. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba17841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and FAISS index\n",
    "model_save_path = '../models/trained_sentiment_model'\n",
    "classifier.save_model(model_save_path)\n",
    "\n",
    "# Save results to CSV\n",
    "results_path = '../data/prediction_results.csv'\n",
    "df.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_save_path}\")\n",
    "print(f\"‚úÖ Results saved to: {results_path}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìä Final Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset size: {len(df)} samples\")\n",
    "print(f\"Overall accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Average confidence: {df['confidence'].mean():.4f}\")\n",
    "print(f\"Classification model: {classifier.classification_model_name}\")\n",
    "print(f\"Embedding model: {classifier.embedding_model_name}\")\n",
    "print(f\"Embedding dimensions: {embeddings.shape[1]}\")\n",
    "print(f\"FAISS index size: {len(classifier.texts_database)} texts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77db2c",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "‚úÖ **Hugging Face Models Integration**\n",
    "- Successfully implemented sentiment classification using `cardiffnlp/twitter-roberta-base-sentiment-latest`\n",
    "- Integrated sentence embeddings using `all-MiniLM-L6-v2`\n",
    "\n",
    "‚úÖ **Embeddings and Similarity Search**\n",
    "- Created high-quality text embeddings for all samples\n",
    "- Built FAISS index for fast similarity search\n",
    "- Demonstrated combined sentiment analysis + similarity search\n",
    "\n",
    "‚úÖ **Comprehensive Evaluation**\n",
    "- Achieved high accuracy on the test dataset\n",
    "- Provided detailed classification metrics\n",
    "- Visualized results with confusion matrix and confidence distributions\n",
    "\n",
    "‚úÖ **Professional Workflow**\n",
    "- Clean, modular code structure\n",
    "- Comprehensive error handling\n",
    "- Detailed documentation and visualizations\n",
    "\n",
    "### Next Steps\n",
    "- Deploy as Streamlit application\n",
    "- Deploy to Hugging Face Spaces\n",
    "- Further model fine-tuning for domain-specific data\n",
    "\n",
    "### Technologies Used\n",
    "- **Models:** Hugging Face Transformers, Sentence-Transformers\n",
    "- **Search:** FAISS vector similarity search\n",
    "- **Visualization:** Matplotlib, Seaborn, Plotly\n",
    "- **Evaluation:** Scikit-learn metrics\n",
    "- **Embeddings Visualization:** t-SNE dimensionality reduction"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
